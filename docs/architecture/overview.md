# System Overview

High-level architecture of MCP-CLI-Go, design philosophy, and system-wide patterns.

---

## Table of Contents

- [System Architecture](#system-architecture)
- [Design Philosophy](#design-philosophy)
- [Layered Architecture](#layered-architecture)
- [Operational Modes](#operational-modes)
- [Provider System](#provider-system)
- [Configuration Architecture](#configuration-architecture)
- [Concurrency Model](#concurrency-model)

---

## System Architecture

### High-Level System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Layer                               â”‚
â”‚  (CLI Commands, Terminal Input, Configuration Files)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Command Layer                               â”‚
â”‚              (Cobra CLI Framework)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  chat    â”‚  query   â”‚interactiveâ”‚ template â”‚  serve   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Service Layer                               â”‚
â”‚           (Business Logic Orchestration)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ ChatService  â”‚ QueryService â”‚ InteractiveServiceâ”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                    â”‚                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Core Layer     â”‚  â”‚ Provider Layer  â”‚  â”‚Infrastructureâ”‚
â”‚                  â”‚  â”‚                 â”‚  â”‚   Layer      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ Chat Manager â”‚ â”‚  â”‚ â”‚ AI Factory â”‚ â”‚  â”‚â”‚Config Svc  â”‚â”‚
â”‚ â”‚              â”‚ â”‚  â”‚ â”‚            â”‚ â”‚  â”‚â”‚            â”‚â”‚
â”‚ â”‚ Query Handlerâ”‚ â”‚  â”‚ â”‚  Clients:  â”‚ â”‚  â”‚â”‚Logger      â”‚â”‚
â”‚ â”‚              â”‚ â”‚  â”‚ â”‚ â€¢ OpenAI   â”‚ â”‚  â”‚â”‚            â”‚â”‚
â”‚ â”‚ Interactive  â”‚ â”‚  â”‚ â”‚ â€¢ Anthropicâ”‚ â”‚  â”‚â”‚Host Mgr    â”‚â”‚
â”‚ â”‚   Service    â”‚ â”‚  â”‚ â”‚ â€¢ Gemini   â”‚ â”‚  â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚              â”‚ â”‚  â”‚ â”‚ â€¢ Ollama   â”‚ â”‚  â”‚              â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚              â”‚
â”‚                  â”‚  â”‚                 â”‚  â”‚              â”‚
â”‚                  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚              â”‚
â”‚                  â”‚  â”‚ â”‚ MCP Proto  â”‚ â”‚  â”‚              â”‚
â”‚                  â”‚  â”‚ â”‚ â€¢ Messages â”‚ â”‚  â”‚              â”‚
â”‚                  â”‚  â”‚ â”‚ â€¢ Transportâ”‚ â”‚  â”‚              â”‚
â”‚                  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                    â”‚                    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Domain Layer                               â”‚
â”‚              (Core Types & Interfaces)                           â”‚
â”‚                                                                  â”‚
â”‚  â€¢ LLMProvider Interface      â€¢ ConfigurationService Interface  â”‚
â”‚  â€¢ CompletionRequest/Response â€¢ Tool Types                      â”‚
â”‚  â€¢ Message Types              â€¢ Error Types                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                    â”‚                    â”‚
          â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  External APIs  â”‚  â”‚   MCP Servers    â”‚  â”‚  File System    â”‚
â”‚                 â”‚  â”‚                  â”‚  â”‚                 â”‚
â”‚ â€¢ OpenAI API    â”‚  â”‚ â€¢ filesystem     â”‚  â”‚ â€¢ Config Files  â”‚
â”‚ â€¢ Anthropic API â”‚  â”‚ â€¢ brave-search   â”‚  â”‚ â€¢ Templates     â”‚
â”‚ â€¢ Gemini API    â”‚  â”‚ â€¢ database       â”‚  â”‚ â€¢ .env          â”‚
â”‚ â€¢ Ollama API    â”‚  â”‚ â€¢ custom servers â”‚  â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Design Philosophy

### Core Principles

#### 1. Separation of Concerns
Each layer has a distinct responsibility:
- **Command Layer:** User interaction and flag parsing
- **Service Layer:** Workflow orchestration
- **Core Layer:** Mode-specific business logic
- **Provider Layer:** External system integration
- **Infrastructure Layer:** Cross-cutting concerns
- **Domain Layer:** Core types and contracts

**Benefit:** Changes in one layer don't cascade to others. Easy to test and maintain.

#### 2. Interface-Based Design
Components communicate through interfaces, not concrete implementations.

```go
// Domain interface
type LLMProvider interface {
    CreateCompletion(ctx context.Context, req *CompletionRequest) (*CompletionResponse, error)
}

// Multiple implementations
type OpenAIClient struct { ... }
type AnthropicClient struct { ... }
type OllamaClient struct { ... }

// All satisfy the same interface
var provider LLMProvider = &OpenAIClient{...}
```

**Benefit:** Easy to swap implementations, mock for testing, and extend.

#### 3. Configuration Over Code
Behavior controlled through configuration:

```yaml
# Change provider without code changes
provider: anthropic  # or openai, gemini, ollama

# Change model without code changes
model: claude-sonnet-4  # or gpt-4o, gemini-pro

# Change templates without code changes
template: code_review  # or security_scan, data_analysis
```

**Benefit:** Users customize behavior. No recompilation needed.

#### 4. Fail-Safe Defaults
System works out of the box with sensible defaults:

```go
// Default to local Ollama if no API keys
if apiKey == "" {
    provider = "ollama"
}

// Default to reasonable token limits
if maxTokens == 0 {
    maxTokens = 4096
}
```

**Benefit:** New users can start immediately.

#### 5. Explicit Over Implicit
Operations are explicit and visible:

```go
// Explicit provider selection
mcp-cli query --provider anthropic "question"

// Explicit template execution  
mcp-cli --template code_review

// Explicit server connection
mcp-cli chat --server filesystem
```

**Benefit:** Users understand what's happening. No surprises.

---

## Layered Architecture

### Layer Responsibilities

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Command Layer (cmd/)                  â”‚
â”‚  Responsibilities:                              â”‚
â”‚  â€¢ Parse CLI flags and arguments               â”‚
â”‚  â€¢ Validate user input                         â”‚
â”‚  â€¢ Invoke appropriate service                  â”‚
â”‚  â€¢ Format and display output                   â”‚
â”‚  Dependencies: Service Layer, Domain Layer     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Service Layer (services/)              â”‚
â”‚  Responsibilities:                              â”‚
â”‚  â€¢ Orchestrate business workflows              â”‚
â”‚  â€¢ Coordinate between providers                â”‚
â”‚  â€¢ Manage transaction boundaries               â”‚
â”‚  â€¢ Handle cross-cutting concerns               â”‚
â”‚  Dependencies: Core, Provider, Infrastructure  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Core   â”‚ â”‚ Provider  â”‚ â”‚Infrastructure â”‚
â”‚  Layer   â”‚ â”‚  Layer    â”‚ â”‚    Layer      â”‚
â”‚          â”‚ â”‚           â”‚ â”‚               â”‚
â”‚ Business â”‚ â”‚ External  â”‚ â”‚ Cross-cutting â”‚
â”‚  Logic   â”‚ â”‚ Integrationsâ”‚ Concerns      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚           â”‚           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Domain Layer (domain/)                 â”‚
â”‚  Responsibilities:                              â”‚
â”‚  â€¢ Define core types and models                â”‚
â”‚  â€¢ Define interfaces (contracts)               â”‚
â”‚  â€¢ Define business rules                       â”‚
â”‚  â€¢ Define domain errors                        â”‚
â”‚  Dependencies: None (pure domain logic)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dependency Rules

**Strict Dependency Direction:**
- Command â†’ Service â†’ Core/Provider/Infrastructure â†’ Domain
- Domain depends on nothing
- Upper layers depend on lower layers
- Lower layers NEVER depend on upper layers

**Dependency Inversion:**
```go
// Service layer depends on interface (Domain)
type ChatService struct {
    provider domain.LLMProvider  // Interface
}

// Provider layer implements interface
type OpenAIClient struct { ... }
func (c *OpenAIClient) CreateCompletion(...) { ... }

// Service is decoupled from concrete provider
```

---

## Operational Modes

### Mode Architecture

Each operational mode has three components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Mode Structure                  â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Command  â”‚â”€â”€â”€â–¶â”‚ Service  â”‚â”€â”€â”€â–¶â”‚  Core  â”‚â”‚
â”‚  â”‚  (CLI)   â”‚    â”‚(Workflow)â”‚    â”‚(Logic) â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚       â”‚                â”‚              â”‚     â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                   â”‚                         â”‚
â”‚             Uses Domain Types               â”‚
â”‚             Uses Providers                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Chat Mode

**Purpose:** Interactive conversation with AI and tools

**Components:**
```
cmd/chat.go
    â†“
services/chat/service.go
    â†“
core/chat/manager.go
    â”œâ”€â†’ AI Provider (streaming)
    â”œâ”€â†’ MCP Servers (tool execution)
    â””â”€â†’ Context Management
```

**Key Characteristics:**
- Maintains conversation context
- Automatic tool execution
- Streaming responses
- Interactive commands (/help, /clear, etc.)

### Query Mode

**Purpose:** Single-shot queries for automation

**Components:**
```
cmd/query.go
    â†“
services/query/service.go
    â†“
core/query/handler.go
    â”œâ”€â†’ AI Provider (completion)
    â”œâ”€â†’ MCP Servers (if needed)
    â””â”€â†’ Output Formatting
```

**Key Characteristics:**
- Stateless (no conversation history)
- Single request-response
- Scriptable
- Multiple output formats (text, JSON)

### Interactive Mode

**Purpose:** Direct MCP server tool testing

**Components:**
```
cmd/interactive.go
    â†“
services/interactive/service.go
    â†“
core/interactive/service.go
    â”œâ”€â†’ MCP Protocol (direct)
    â””â”€â†’ Tool Inspection
```

**Key Characteristics:**
- No AI involvement
- Manual tool calling
- Direct MCP communication
- Tool schema inspection

### Workflow Mode

**Purpose:** Multi-step AI workflows

**Components:**
```
cmd/root.go (--template flag)
    â†“
services/template/executor.go
    â†“
core/template/engine.go
    â”œâ”€â†’ Template Parser
    â”œâ”€â†’ Variable Substitution
    â”œâ”€â†’ Step Execution
    â”‚   â”œâ”€â†’ AI Provider
    â”‚   â””â”€â†’ MCP Servers
    â””â”€â†’ Result Aggregation
```

**Key Characteristics:**
- Multi-step execution
- Variable interpolation
- Conditional logic
- Template composition

### Server Mode

**Purpose:** Expose templates as MCP server

**Components:**
```
cmd/serve.go
    â†“
services/server/service.go
    â†“
core/server/handler.go
    â”œâ”€â†’ JSON-RPC Server
    â”œâ”€â†’ Tool Registration
    â”œâ”€â†’ Template Mapping
    â””â”€â†’ Parameter Translation
```

**Key Characteristics:**
- JSON-RPC protocol
- Tool discovery
- Parameter mapping
- Template execution

---

## Provider System

### Provider Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Provider Factory Pattern               â”‚
â”‚                                                  â”‚
â”‚  Request: (providerType, config)                â”‚
â”‚      â”‚                                           â”‚
â”‚      â–¼                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚         Provider Factory             â”‚       â”‚
â”‚  â”‚  â€¢ Maps type to implementation       â”‚       â”‚
â”‚  â”‚  â€¢ Creates provider instance          â”‚       â”‚
â”‚  â”‚  â€¢ Validates configuration            â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚      â”‚                                           â”‚
â”‚      â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚      â–¼      â–¼      â–¼      â–¼      â–¼      â–¼       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â” â”‚
â”‚  â”‚OpenAIâ”‚â”‚Anthrâ”‚â”‚Geminiâ”‚â”‚Ollamaâ”‚â”‚DeepS.â”‚â”‚OR  â”‚ â”‚
â”‚  â”‚Clientâ”‚â”‚opicCâ”‚â”‚Clientâ”‚â”‚Clientâ”‚â”‚Clientâ”‚â”‚Clntâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜ â”‚
â”‚                                                  â”‚
â”‚  All implement: domain.LLMProvider interface    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Interface Types

Providers are categorized by interface compatibility:

```go
type InterfaceType string

const (
    OpenAICompatible InterfaceType = "openai_compatible"
    AnthropicNative  InterfaceType = "anthropic_native"
    GeminiNative     InterfaceType = "gemini_native"
    OllamaNative     InterfaceType = "ollama_native"
)
```

**OpenAI-Compatible Providers:**
- OpenAI (official)
- DeepSeek
- OpenRouter
- Any provider with OpenAI-compatible API

**Native Providers:**
- Anthropic (streaming, tool use)
- Gemini (native protocol)
- Ollama (local inference)

### Provider Selection Flow

```
User Request
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Determine Provider      â”‚
â”‚ 1. CLI flag (--provider)â”‚
â”‚ 2. Config default       â”‚
â”‚ 3. Template override    â”‚
â”‚ 4. System default       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Validate Configuration  â”‚
â”‚ â€¢ API key present?      â”‚
â”‚ â€¢ Model available?      â”‚
â”‚ â€¢ Network accessible?   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Create Provider Instanceâ”‚
â”‚ via Factory             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute Request         â”‚
â”‚ â€¢ Retry on failure      â”‚
â”‚ â€¢ Stream if supported   â”‚
â”‚ â€¢ Handle tools          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Configuration Architecture

### Configuration Hierarchy

MCP-CLI uses a sophisticated configuration hierarchy that allows flexible overrides at multiple levels:

```
Command Line Args (Highest Priority)
         â†“
    --provider anthropic
    --model claude-sonnet-4
         â†“
Environment Variables  
         â†“
    OPENAI_API_KEY=sk-...
    MCP_PROVIDER=anthropic
         â†“
Enhanced Configuration (config.yaml - interfaces)
         â†“
    ai:
      default_provider: anthropic
      interfaces:
        openai_compatible: {...}
        anthropic_native: {...}
         â†“
Legacy Configuration (providers - backward compatibility)
         â†“
    providers:
      - provider_name: openai
        api_key: ${OPENAI_API_KEY}
         â†“
System Defaults (Lowest Priority)
         â†“
    provider: ollama
    model: llama3.1:8b
```

**Resolution Process:**

1. **CLI flags** override everything
2. **Environment variables** override configuration files
3. **Enhanced config** takes precedence over legacy
4. **Legacy config** provides backward compatibility
5. **System defaults** ensure operation without configuration

### Configuration Structure

```yaml
# config.yaml - Modern structure
version: 2.0

ai:
  default_provider: anthropic
  
  interfaces:
    openai_compatible:
      providers:
        openai:
          api_key: ${OPENAI_API_KEY}
          default_model: gpt-4o
          api_endpoint: https://api.openai.com/v1
        
        deepseek:
          api_key: ${DEEPSEEK_API_KEY}
          default_model: deepseek-chat
          api_endpoint: https://api.deepseek.com/v1
    
    anthropic_native:
      providers:
        anthropic:
          api_key: ${ANTHROPIC_API_KEY}
          default_model: claude-sonnet-4
          api_endpoint: https://api.anthropic.com

mcp:
  servers:
    filesystem:
      command: filesystem-server
      args: []
    
    brave_search:
      command: brave-search-server
      env:
        BRAVE_API_KEY: ${BRAVE_API_KEY}

templates:
  paths:
    - ./config/templates
    - ./templates
  
  defaults:
    provider: anthropic
    model: claude-sonnet-4
```

### Configuration Loading Process

```
Application Start
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load config.yaml        â”‚
â”‚ â€¢ Parse YAML            â”‚
â”‚ â€¢ Expand env vars       â”‚
â”‚ â€¢ Validate schema       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Provider Configs   â”‚
â”‚ â€¢ Load from config/     â”‚
â”‚ â€¢ Merge with main       â”‚
â”‚ â€¢ Validate credentials  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load MCP Server Configs â”‚
â”‚ â€¢ Load from config/     â”‚
â”‚ â€¢ Validate binaries     â”‚
â”‚ â€¢ Check permissions     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Templates          â”‚
â”‚ â€¢ Scan template paths   â”‚
â”‚ â€¢ Parse YAML            â”‚
â”‚ â€¢ Build template index  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Configuration Ready     â”‚
â”‚ â€¢ Provider factory init â”‚
â”‚ â€¢ Server manager init   â”‚
â”‚ â€¢ Template engine init  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Concurrency Model

### Goroutine Usage

```
Main Process
    â”‚
    â”œâ”€â”€â”€ MCP Server 1 (goroutine)
    â”‚    â”œâ”€â”€â”€ Tool execution (goroutine)
    â”‚    â””â”€â”€â”€ Heartbeat monitor (goroutine)
    â”‚
    â”œâ”€â”€â”€ MCP Server 2 (goroutine)
    â”‚    â””â”€â”€â”€ Tool execution (goroutine)
    â”‚
    â”œâ”€â”€â”€ Streaming Response Processor (goroutine)
    â”‚    â”œâ”€â”€â”€ Chunk reader
    â”‚    â”œâ”€â”€â”€ Chunk writer
    â”‚    â””â”€â”€â”€ Buffer management
    â”‚
    â””â”€â”€â”€ User Input Handler (goroutine, chat mode)
         â””â”€â”€â”€ Command processing
```

### Synchronization Patterns

**Context for Cancellation:**
```go
ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
defer cancel()

response, err := provider.CreateCompletion(ctx, request)
```

**Channels for Communication:**
```go
type StreamProcessor struct {
    chunks  chan string        // Data flow
    errors  chan error         // Error reporting
    done    chan bool          // Completion signal
}
```

**Mutex for Shared State:**
```go
type ChatContext struct {
    mu       sync.RWMutex
    messages []domain.Message
    
    func (c *ChatContext) AddMessage(msg domain.Message) {
        c.mu.Lock()
        defer c.mu.Unlock()
        c.messages = append(c.messages, msg)
    }
}
```

### MCP Server Process Management

```
Server Manager
    â”‚
    â”œâ”€â”€â”€ Start Server Process
    â”‚    â”œâ”€â”€â”€ exec.Command(serverPath)
    â”‚    â”œâ”€â”€â”€ Set stdio pipes
    â”‚    â”œâ”€â”€â”€ Start process
    â”‚    â””â”€â”€â”€ Store process handle
    â”‚
    â”œâ”€â”€â”€ Monitor Health (goroutine)
    â”‚    â”œâ”€â”€â”€ Periodic ping
    â”‚    â”œâ”€â”€â”€ Check process alive
    â”‚    â””â”€â”€â”€ Restart if crashed
    â”‚
    â”œâ”€â”€â”€ Handle Tool Calls
    â”‚    â”œâ”€â”€â”€ Send JSON-RPC request
    â”‚    â”œâ”€â”€â”€ Wait for response
    â”‚    â””â”€â”€â”€ Parse result
    â”‚
    â””â”€â”€â”€ Shutdown
         â”œâ”€â”€â”€ Send shutdown message
         â”œâ”€â”€â”€ Wait for graceful exit
         â””â”€â”€â”€ Force kill if timeout
```

---

## Error Handling Architecture

### Error Flow

```
Error Occurs
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classify Error          â”‚
â”‚ â€¢ User error            â”‚
â”‚ â€¢ System error          â”‚
â”‚ â€¢ Provider error        â”‚
â”‚ â€¢ Network error         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Determine Handling      â”‚
â”‚ â€¢ Retryable?            â”‚
â”‚ â€¢ Recoverable?          â”‚
â”‚ â€¢ Fatal?                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
    â”‚    â”‚    â”‚
    â–¼    â–¼    â–¼
â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”
â”‚Retryâ”‚â”‚Logâ”‚â”‚Exitâ”‚
â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜
```

### Retry Logic

```go
type RetryConfig struct {
    MaxAttempts  int
    InitialDelay time.Duration
    MaxDelay     time.Duration
    Multiplier   float64
}

func retryWithBackoff(operation func() error, config RetryConfig) error {
    delay := config.InitialDelay
    
    for attempt := 0; attempt < config.MaxAttempts; attempt++ {
        err := operation()
        if err == nil {
            return nil
        }
        
        if !isRetryable(err) {
            return err
        }
        
        time.Sleep(delay)
        delay = time.Duration(float64(delay) * config.Multiplier)
        if delay > config.MaxDelay {
            delay = config.MaxDelay
        }
    }
    
    return fmt.Errorf("operation failed after %d attempts", config.MaxAttempts)
}
```

---

## Performance Characteristics

### Request Latency

```
Component                 Latency
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CLI Parsing               < 1ms
Config Loading            < 10ms
Provider Selection        < 1ms
Template Parsing          < 5ms
MCP Server Connection     < 50ms
AI API Call               500-5000ms  (variable)
Tool Execution            10-1000ms   (tool-dependent)
Response Formatting       < 10ms
Total (simple query)      500-6000ms
Total (with tools)        1000-10000ms
```

### Memory Usage

```
Component                 Memory
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Base Application          20-30 MB
Configuration             1-5 MB
Chat Context              5-50 MB    (grows with history)
Template Cache            1-10 MB
MCP Server Process        10-50 MB   (per server)
Provider Client           5-20 MB
Stream Buffer             1-5 MB
Total (typical)           50-200 MB
```

---

---

## State Management Strategy

### Stateful vs. Stateless Operations

**Stateless Operations (Query, Template):**
- No conversation history
- Each request independent
- No shared state between requests
- Memory released after completion

**Stateful Operations (Chat, Server):**
- Conversation history maintained
- Context carries across requests
- Shared state requires synchronization
- Memory grows with usage

### Chat State Management

**State Components:**
```go
type ChatContext struct {
    mu           sync.RWMutex
    messages     []Message          // Conversation history
    systemPrompt string            // System instructions
    metadata     map[string]interface{}  // Session metadata
    
    // Resource management
    maxMessages  int               // Trim threshold
    tokenBudget  int               // Token limit
}
```

**State Lifecycle:**

```
Session Start
    â”‚
    â–¼
Initialize Context
    â”œâ”€â†’ Load system prompt
    â”œâ”€â†’ Set resource limits
    â””â”€â†’ Initialize metadata
    â”‚
    â–¼
Message Loop
    â”œâ”€â†’ Add user message â†’ Lock
    â”œâ”€â†’ Generate response â†’ Lock
    â”œâ”€â†’ Add assistant message â†’ Lock
    â”œâ”€â†’ Check limits â†’ Trim if needed
    â”‚
    â–¼
Session End
    â””â”€â†’ Release resources
```

**Concurrency Control:**
- Read-write mutex for message list
- Single-writer guarantee (only chat manager modifies)
- Multiple readers allowed (context inspection)
- Lock granularity: per-operation, not per-message

**Memory Management:**
```go
func (c *ChatContext) trimMessages() {
    c.mu.Lock()
    defer c.mu.Unlock()
    
    if len(c.messages) <= c.maxMessages {
        return
    }
    
    // Keep system prompt + recent messages
    systemMsg := c.messages[0]
    recentMessages := c.messages[len(c.messages)-c.maxMessages+1:]
    
    c.messages = append([]Message{systemMsg}, recentMessages...)
    
    runtime.GC()  // Hint to GC to reclaim old messages
}
```

### MCP Server State

**Server Connection State:**
```go
type ServerState int

const (
    StateUninitialized ServerState = iota
    StateConnecting
    StateInitialized
    StateReady
    StateError
    StateStopped
)

type ServerConnection struct {
    mu      sync.RWMutex
    state   ServerState
    process *exec.Cmd
    toolCache map[string][]Tool  // Cached tool list
}
```

**State Transitions:**
```
Uninitialized
    â”‚
    â”œâ”€â†’ Start() â†’ Connecting
    â”‚                â”‚
    â”‚                â”œâ”€â†’ Success â†’ Initialized
    â”‚                â”‚                â”‚
    â”‚                â”‚                â”œâ”€â†’ ListTools() â†’ Ready
    â”‚                â”‚                â”‚
    â”‚                â”‚                â””â”€â†’ Error â†’ Error
    â”‚                â”‚
    â”‚                â””â”€â†’ Failure â†’ Error
    â”‚
    â””â”€â†’ Any State â†’ Stop() â†’ Stopped
```

**Race Condition Prevention:**
```go
func (s *ServerConnection) GetTools() ([]Tool, error) {
    s.mu.RLock()
    if s.state != StateReady {
        s.mu.RUnlock()
        return nil, errors.New("server not ready")
    }
    
    // Check cache
    if tools, ok := s.toolCache["tools"]; ok {
        s.mu.RUnlock()
        return tools, nil
    }
    s.mu.RUnlock()
    
    // Need to fetch - upgrade to write lock
    s.mu.Lock()
    defer s.mu.Unlock()
    
    // Double-check after acquiring write lock
    if tools, ok := s.toolCache["tools"]; ok {
        return tools, nil
    }
    
    // Fetch and cache
    tools, err := s.fetchTools()
    if err == nil {
        s.toolCache["tools"] = tools
    }
    return tools, err
}
```

---

## Distributed System Concerns

### Process Coordination

**Challenge:** MCP servers run as separate processes. Must coordinate:
- Server lifecycle (start, stop, restart)
- Request/response correlation
- Concurrent tool calls
- Failure detection and recovery

**Solution: Process Manager Pattern**

```go
type ProcessManager struct {
    mu        sync.RWMutex
    processes map[string]*ManagedProcess
}

type ManagedProcess struct {
    cmd       *exec.Cmd
    stdin     io.WriteCloser
    stdout    io.ReadCloser
    stderr    io.ReadCloser
    
    // Coordination
    requests  map[int]chan Response  // Request ID â†’ response channel
    requestMu sync.Mutex
    nextID    int
    
    // Health monitoring
    healthy   bool
    lastPing  time.Time
}
```

**Request Correlation:**
```go
func (p *ManagedProcess) SendRequest(ctx context.Context, method string, params interface{}) (Response, error) {
    // Allocate request ID
    p.requestMu.Lock()
    id := p.nextID
    p.nextID++
    responseChan := make(chan Response, 1)
    p.requests[id] = responseChan
    p.requestMu.Unlock()
    
    // Send request
    request := JSONRPCRequest{ID: id, Method: method, Params: params}
    json.NewEncoder(p.stdin).Encode(request)
    
    // Wait for response with timeout
    select {
    case response := <-responseChan:
        return response, nil
    case <-ctx.Done():
        return Response{}, ctx.Err()
    case <-time.After(30 * time.Second):
        return Response{}, errors.New("request timeout")
    }
}

// Response handler goroutine
func (p *ManagedProcess) handleResponses() {
    scanner := bufio.NewScanner(p.stdout)
    for scanner.Scan() {
        var response JSONRPCResponse
        json.Unmarshal(scanner.Bytes(), &response)
        
        p.requestMu.Lock()
        if ch, ok := p.requests[response.ID]; ok {
            ch <- response.Result
            delete(p.requests, response.ID)
        }
        p.requestMu.Unlock()
    }
}
```

### Partial Failure Handling

**Scenario:** User requests analysis that requires 3 tools. Tool 1 succeeds, Tool 2 fails, Tool 3 succeeds.

**Strategy:** Collect all results, return partial success with errors.

```go
type ToolResult struct {
    ToolName string
    Success  bool
    Result   interface{}
    Error    error
}

func (m *Manager) ExecuteTools(ctx context.Context, toolCalls []ToolCall) []ToolResult {
    results := make([]ToolResult, len(toolCalls))
    var wg sync.WaitGroup
    
    for i, call := range toolCalls {
        wg.Add(1)
        go func(idx int, tc ToolCall) {
            defer wg.Done()
            
            result, err := m.executeSingleTool(ctx, tc)
            results[idx] = ToolResult{
                ToolName: tc.ToolName,
                Success:  err == nil,
                Result:   result,
                Error:    err,
            }
        }(i, call)
    }
    
    wg.Wait()
    return results  // Returns all results, even if some failed
}
```

**AI Provider receives:**
```json
{
  "tool_results": [
    {"tool": "analyze_code", "success": true, "result": "..."},
    {"tool": "check_security", "success": false, "error": "server timeout"},
    {"tool": "suggest_improvements", "success": true, "result": "..."}
  ]
}
```

**AI can decide:** Continue with partial results or retry failed tools.

### Timeout and Deadline Propagation

**Problem:** Nested operations need coordinated timeouts.

```
User Request (30s timeout)
    â”‚
    â”œâ”€â†’ Chat Service (25s remaining)
    â”‚       â”‚
    â”‚       â”œâ”€â†’ AI Provider Call (20s remaining)
    â”‚       â”‚       â”‚
    â”‚       â”‚       â””â”€â†’ Network Request (15s remaining)
    â”‚       â”‚
    â”‚       â””â”€â†’ Tool Execution (10s remaining)
    â”‚               â”‚
    â”‚               â””â”€â†’ MCP Server Call (5s remaining)
```

**Solution: Context-based deadline propagation**

```go
func ProcessUserRequest(userTimeout time.Duration) error {
    // Create parent context with deadline
    ctx, cancel := context.WithTimeout(context.Background(), userTimeout)
    defer cancel()
    
    // Pass context down - automatically inherits deadline
    return chatService.HandleMessage(ctx, message)
}

func (s *ChatService) HandleMessage(ctx context.Context, msg string) error {
    // Check if we still have time
    if deadline, ok := ctx.Deadline(); ok {
        remaining := time.Until(deadline)
        if remaining < 5*time.Second {
            return errors.New("insufficient time remaining")
        }
    }
    
    // Call provider - automatically respects parent deadline
    return s.provider.CreateCompletion(ctx, request)
}
```

---

## Bounded Contexts and Domain Boundaries

### Context Map

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Command Context (CLI)                   â”‚
â”‚                                                      â”‚
â”‚  Responsibility: User interaction, routing           â”‚
â”‚  Language: Commands, flags, arguments                â”‚
â”‚  Dependencies: None (entry point)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ Commands
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Execution Context (Business Logic)         â”‚
â”‚                                                      â”‚
â”‚  Responsibility: Workflow orchestration              â”‚
â”‚  Language: Services, handlers, managers              â”‚
â”‚  Dependencies: Domain, Provider, Infrastructure      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ Requests
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Provider Context (Integration)             â”‚
â”‚                                                      â”‚
â”‚  Responsibility: External system communication       â”‚
â”‚  Language: Clients, adapters, protocols              â”‚
â”‚  Dependencies: Domain (interfaces only)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Anti-Corruption Layers

**Problem:** External APIs have different models than our domain.

**Solution:** Adapter pattern with translation layer.

```go
// Domain model (our language)
type CompletionRequest struct {
    Messages    []Message
    MaxTokens   int
    Temperature float64
}

// OpenAI API model (their language)
type OpenAIRequest struct {
    Model       string                 `json:"model"`
    Messages    []OpenAIMessage        `json:"messages"`
    MaxTokens   int                    `json:"max_tokens"`
    Temperature float64                `json:"temperature"`
}

// Anti-corruption layer
func (c *OpenAIClient) CreateCompletion(req *CompletionRequest) (*CompletionResponse, error) {
    // Translate our model to their model
    apiReq := &OpenAIRequest{
        Model:       c.model,
        Messages:    convertMessages(req.Messages),  // Translation
        MaxTokens:   req.MaxTokens,
        Temperature: req.Temperature,
    }
    
    // Call their API
    apiResp, err := c.callOpenAI(apiReq)
    
    // Translate their model back to our model
    return convertResponse(apiResp), err  // Translation
}
```

**Benefit:** Domain model stays clean. API changes isolated to adapter.

---

## Scalability Analysis

### Vertical Scaling (Single Instance)

**Current Limits:**

| Resource | Limit | Reason |
|----------|-------|--------|
| **Chat Context** | 1000 messages | Memory growth (500MB) |
| **Concurrent MCP Servers** | 20 servers | Memory overhead (1GB) |
| **Template Nesting** | 10 levels | Stack depth |
| **Concurrent Tool Calls** | 1000 goroutines | Goroutine overhead |

**Bottlenecks:**
1. **Memory** - Linear growth with chat history and MCP servers
2. **Provider API Rate Limits** - External constraint
3. **Sequential Template Steps** - Can't parallelize without refactoring

**Optimization Strategies:**
- Context compression (summarize old messages)
- Lazy MCP server loading
- Template step parallelization (future)
- Response caching

### Horizontal Scaling (Multiple Instances)

**Current State:** Not supported (no shared state mechanism)

**Challenges:**
- Chat sessions are stateful (can't distribute)
- MCP servers are process-local (can't share)
- No coordination mechanism

**Future Architecture for Scale:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MCP-CLI     â”‚   â”‚ MCP-CLI     â”‚   â”‚ MCP-CLI     â”‚
â”‚ Instance 1  â”‚   â”‚ Instance 2  â”‚   â”‚ Instance 3  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                    â”‚  Redis   â”‚  Shared state
                    â”‚ (Cache)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Required Changes:**
- Externalize chat context (Redis/PostgreSQL)
- Centralized MCP server pool
- Session affinity or sticky routing
- Distributed locking

---

## Performance Optimization Patterns

### 1. Connection Pooling

**Problem:** Creating new HTTP connection for each API call is slow.

**Solution:** Reuse connections via `http.Client` connection pool.

```go
func newHTTPClient() *http.Client {
    return &http.Client{
        Transport: &http.Transport{
            // Connection pooling
            MaxIdleConns:        100,
            MaxIdleConnsPerHost: 10,
            IdleConnTimeout:     90 * time.Second,
            
            // Connection reuse
            DisableKeepAlives: false,
            
            // TLS optimization
            TLSHandshakeTimeout: 10 * time.Second,
        },
        Timeout: 30 * time.Second,
    }
}
```

**Benefit:** 50-100ms latency reduction per API call (eliminates TCP handshake + TLS handshake).

### 2. Tool Discovery Caching

**Problem:** Listing tools from MCP server requires JSON-RPC call.

**Solution:** Cache tool list after first retrieval.

```go
func (m *ServerManager) GetTools(serverName string) ([]Tool, error) {
    m.cacheMu.RLock()
    if tools, ok := m.toolCache[serverName]; ok {
        m.cacheMu.RUnlock()
        return tools, nil  // Return cached
    }
    m.cacheMu.RUnlock()
    
    // Fetch from server
    tools, err := m.fetchToolsFromServer(serverName)
    if err != nil {
        return nil, err
    }
    
    // Cache for future calls
    m.cacheMu.Lock()
    m.toolCache[serverName] = tools
    m.cacheMu.Unlock()
    
    return tools, nil
}
```

**Benefit:** 10-50ms latency reduction for subsequent tool calls.

### 3. Streaming Response Processing

**Problem:** Waiting for complete response before displaying is slow UX.

**Solution:** Stream chunks as they arrive.

```go
func (c *Client) StreamCompletion(ctx context.Context, req *CompletionRequest, writer io.Writer) error {
    // Make request
    resp, err := c.httpClient.Do(httpReq)
    defer resp.Body.Close()
    
    // Process Server-Sent Events
    scanner := bufio.NewScanner(resp.Body)
    for scanner.Scan() {
        line := scanner.Text()
        
        if strings.HasPrefix(line, "data: ") {
            chunk := parseChunk(line)
            writer.Write([]byte(chunk.Content))  // Immediate display
        }
    }
}
```

**Benefit:** First token appears ~500ms faster. Better perceived performance.

### 4. Goroutine Pooling (Not Implemented)

**Problem:** Creating 1000 goroutines for 1000 tool calls has overhead.

**Proposed Solution:** Worker pool pattern.

```go
type WorkerPool struct {
    workers   int
    taskQueue chan func()
}

func NewWorkerPool(workers int) *WorkerPool {
    pool := &WorkerPool{
        workers:   workers,
        taskQueue: make(chan func(), workers*2),
    }
    
    for i := 0; i < workers; i++ {
        go pool.worker()
    }
    
    return pool
}

func (p *WorkerPool) worker() {
    for task := range p.taskQueue {
        task()  // Execute task
    }
}

func (p *WorkerPool) Submit(task func()) {
    p.taskQueue <- task
}
```

**Benefit:** Reduced goroutine creation overhead for large batches.

---

## Next Steps

- **[Components](components.md)** - Detailed component architecture
- **[Data Flow](data-flow.md)** - Request/response flows
- **[API & Domain](api-domain.md)** - Interfaces and types

---

**Understanding the architecture?** Continue to [Components](components.md) for detailed component design. ğŸ—ï¸
