$schema: "workflow/v2.0"
name: rag_pipeline_builder
version: 2.0.0
description: Build RAG pipeline with systematic parse → chunk → embed → validate workflow

execution:
  provider: anthropic
  model: claude-sonnet-4
  temperature: 0.3
  servers: [filesystem]

steps:
  # Step 1: Parse and extract text from documents
  - name: parse_documents
    run: |
      Parse these documents and extract text:
      
      {{input}}
      
      For each document:
      
      **Document Analysis:**
      - Format: [PDF, Markdown, HTML, Code, Plain Text]
      - Length: [character count]
      - Structure: [Headers, sections, code blocks]
      - Language: [detected language]
      
      **Text Extraction:**
      - Clean text content
      - Preserve structure (headers, lists)
      - Remove noise (boilerplate, navigation)
      - Extract metadata (title, author, date)
      
      **Quality Checks:**
      - Text extracted successfully: [Yes/No]
      - Encoding issues: [None/List issues]
      - Missing content: [None/List gaps]
      - Special handling needed: [None/List]
      
      Return structured JSON with:
      ```json
      {
        "documents": [
          {
            "id": "doc_001",
            "source": "filename.pdf",
            "format": "PDF",
            "text": "extracted text...",
            "metadata": {...},
            "length": 5000,
            "quality": "good"
          }
        ]
      }
      ```

  # Step 2: Chunk text into embedding-sized pieces
  - name: chunk_text
    needs: [parse_documents]
    run: |
      Chunk the extracted text for embeddings:
      
      Parsed Documents:
      {{parse_documents}}
      
      **Chunking Strategy:**
      
      **1. Semantic Chunking (Preferred):**
      - Split at natural boundaries (paragraphs, sections)
      - Preserve complete thoughts
      - Maintain context within chunks
      
      **2. Size Targets:**
      - Target: 500-1000 tokens per chunk
      - Maximum: 1500 tokens
      - Minimum: 100 tokens (avoid tiny chunks)
      
      **3. Overlap:**
      - 50-100 token overlap between chunks
      - Preserves context across boundaries
      - Helps with retrieval quality
      
      **4. Metadata Preservation:**
      - Source document
      - Chunk position (1 of N)
      - Section/heading context
      - Original page/location
      
      For each chunk, provide:
      ```json
      {
        "chunk_id": "doc_001_chunk_001",
        "source_doc": "doc_001",
        "text": "chunk text...",
        "tokens": 800,
        "position": 1,
        "total_chunks": 10,
        "metadata": {
          "section": "Introduction",
          "page": 1
        }
      }
      ```
      
      **Quality Validation:**
      - All chunks within size limits: [Yes/No]
      - No orphaned incomplete sentences: [Yes/No]
      - Context preserved: [Yes/No]
      - Total chunks: [count]

  # Step 3: Generate embedding plan
  - name: plan_embeddings
    needs: [chunk_text]
    run: |
      Create embedding generation plan:
      
      Chunks: {{chunk_text}}
      
      **Embedding Configuration:**
      
      **Model Selection:**
      - Model: text-embedding-3-small (OpenAI)
      - Dimensions: 1536
      - Cost: $0.02 per 1M tokens
      
      **Batch Processing:**
      - Total chunks: [count from chunk_text]
      - Batch size: 100 chunks
      - Number of batches: [calculate]
      - Estimated tokens: [sum of all chunks]
      - Estimated cost: $[calculate]
      
      **Processing Strategy:**
      - Batch chunks to minimize API calls
      - Rate limiting: 3000 RPM
      - Retry on failure: 3 attempts
      - Error handling: Skip bad chunks, log for review
      
      **Quality Checks:**
      - Validate chunk text before embedding
      - Check for empty/null chunks
      - Verify token counts
      - Detect duplicates
      
      **Output Format:**
      ```json
      {
        "embedding_plan": {
          "model": "text-embedding-3-small",
          "total_chunks": 156,
          "batches": 2,
          "estimated_tokens": 124000,
          "estimated_cost": 0.00248,
          "processing_time_estimate": "30 seconds"
        }
      }
      ```

  # Step 4: Validate pipeline before execution
  - name: validate_pipeline
    needs: [parse_documents, chunk_text, plan_embeddings]
    run: |
      Validate RAG pipeline before executing embeddings:
      
      Documents: {{parse_documents}}
      Chunks: {{chunk_text}}
      Plan: {{plan_embeddings}}
      
      **Validation Checks:**
      
      **1. Document Quality:**
      - All documents parsed successfully: [Yes/No]
      - Text extraction quality: [Good/Fair/Poor]
      - Any encoding issues: [None/List]
      - Missing content: [None/List]
      
      **2. Chunking Quality:**
      - All chunks within size limits: [Yes/No]
      - Average chunk size: [tokens]
      - Min/max chunk sizes: [tokens]
      - Context preserved: [Yes/No]
      - No duplicate chunks: [Yes/No]
      
      **3. Cost Validation:**
      - Estimated embedding cost: $[from plan]
      - Within budget: [Yes/No if budget provided]
      - Cost per document: $[calculate]
      - Cost efficient: [Yes/No, compare to alternatives]
      
      **4. Pipeline Readiness:**
      - Ready to proceed: [Yes/No]
      - Warnings: [List any concerns]
      - Recommendations: [List improvements]
      
      **Decision:**
      - **PROCEED:** Pipeline validated, ready for embeddings
      - **REVIEW:** Issues found, review before proceeding
      - **ABORT:** Critical issues, do not proceed
      
      **If PROCEED:**
      Provide exact batch processing commands:
      ```bash
      # Batch 1
      curl https://api.openai.com/v1/embeddings \
        -H "Authorization: Bearer $OPENAI_API_KEY" \
        -d '{"input": ["chunk1", "chunk2"...], "model": "text-embedding-3-small"}'
      
      # Store in vector database
      # INSERT INTO embeddings (chunk_id, vector, metadata) VALUES (...)
      ```

  # Step 5: Generate pipeline report
  - name: pipeline_report
    needs: [validate_pipeline]
    run: |
      Generate comprehensive RAG pipeline report:
      
      # RAG Pipeline Construction Report
      
      **Generated:** {{execution.timestamp}}
      **Workflow:** {{workflow.name}} v{{workflow.version}}
      
      ---
      
      ## Pipeline Overview
      
      **Documents Processed:** [count]
      **Total Chunks Generated:** [count]
      **Embedding Model:** text-embedding-3-small
      **Estimated Cost:** $[amount]
      
      ---
      
      ## Document Parsing
      
      {{parse_documents}}
      
      **Summary:**
      - Successfully parsed: [count]
      - Parsing errors: [count]
      - Total text extracted: [character count]
      
      ---
      
      ## Text Chunking
      
      {{chunk_text}}
      
      **Summary:**
      - Total chunks: [count]
      - Average chunk size: [tokens]
      - Size range: [min]-[max] tokens
      - Overlap: 50-100 tokens
      
      ---
      
      ## Embedding Plan
      
      {{plan_embeddings}}
      
      **Cost Breakdown:**
      - Tokens to embed: [count]
      - Cost per token: $0.00000002
      - Total cost: $[amount]
      - Cost per document: $[amount]
      
      ---
      
      ## Validation Results
      
      {{validate_pipeline}}
      
      ---
      
      ## Next Steps
      
      **If PROCEED:**
      
      1. **Execute Embeddings:**
         ```bash
         # Run provided batch commands
         # Or use batch processing script
         ```
      
      2. **Store in Vector Database:**
         - Database: [Pinecone, Weaviate, pgvector, etc.]
         - Index configuration: [settings]
         - Metadata fields: [list]
      
      3. **Test Retrieval:**
         ```python
         # Test query
         query = "What is RAG?"
         results = vector_db.similarity_search(query, k=5)
         ```
      
      4. **Build RAG Application:**
         - Query → Embed → Search → Retrieve → Generate
      
      **If REVIEW or ABORT:**
      
      1. Fix identified issues
      2. Re-run pipeline
      3. Validate again
      
      ---
      
      ## Quality Metrics
      
      **Document Quality:** [Good/Fair/Poor]
      **Chunk Quality:** [Good/Fair/Poor]
      **Cost Efficiency:** [Good/Fair/Poor]
      **Pipeline Ready:** [Yes/No]
      
      ---
      
      ## Business Value
      
      **Time Savings:**
      - Manual pipeline setup: 8 hours
      - Automated workflow: 5 minutes
      - Savings: 7h 55min (99%)
      
      **Quality Assurance:**
      - Systematic validation prevents bad embeddings
      - Cost estimate before spending
      - Quality checks at each stage
      
      **Cost Control:**
      - Estimated cost: $[amount]
      - Per-document cost: $[amount]
      - ROI: High (reusable embeddings)

# Usage:
#
# Build RAG pipeline from documents:
# ./mcp-cli --workflow rag_pipeline_builder \
#   --server filesystem \
#   --input-data "$(cat docs/*.md)"
#
# From specific document collection:
# ./mcp-cli --workflow rag_pipeline_builder \
#   --server filesystem \
#   --input-data '{
#     "documents": ["doc1.pdf", "doc2.md", "doc3.txt"]
#   }'
#
# Business Value:
# - Systematic RAG pipeline construction
# - Quality validation at each stage
# - Cost estimation before execution
# - Prevents bad embeddings from poor chunking
# - Step dependencies ensure nothing skipped
#
# ROI Calculation:
# - Manual pipeline setup: 8 hours × $150/hour = $1,200
# - Automated: 5 minutes × $0.05 = $0.05
# - Savings: $1,199.95 per pipeline (99.996%)
#
# Cost Control:
# - Validates before spending on embeddings
# - Prevents wasted API costs on bad data
# - Typical embedding cost: $0.02-0.20 per document
# - Validation prevents 100% waste if bad chunking
#
# Quality Improvements:
# - Systematic chunking ensures context preserved
# - Validation catches issues early
# - Cost-effective embedding strategy
# - Ready for production RAG applications
