name: resilient_analysis
description: "Demonstrates error handling and retry logic"
version: 1.0.0

metadata:
  category: example
  tags:
    - error-handling
    - resilience

config:
  variables:
    max_attempts: "3"
  
  defaults:
    provider: openai
    model: gpt-4o-mini
    temperature: 0.5
    timeout: 120s
  
  error_handling:
    on_failure: continue
    max_retries: 2

steps:
  # Step 1: Primary data fetch with retry
  - name: fetch_data
    description: "Fetch data with retry logic"
    
    prompt: |
      Fetch and analyze data for: {{input_data}}
      
      Provide comprehensive analysis.
    
    servers: []
    
    error_handling:
      on_failure: retry
      max_retries: 3
      retry_backoff: exponential
      initial_delay: 1s
      timeout: 60s
    
    output: primary_data
  
  # Step 2: Process the fetched data
  - name: process_data
    description: "Process the fetched data"
    depends_on:
      - fetch_data
    
    prompt: |
      Process this data:
      {{primary_data}}
      
      Extract key insights and metrics.
    
    servers: []
    
    error_handling:
      on_failure: continue
      default_output: "Processing failed - using defaults"
    
    output: processed_data
  
  # Step 3: Validation with fallback
  - name: validate_results
    description: "Validate results with error handling"
    depends_on:
      - process_data
    
    prompt: |
      Validate this processed data:
      {{processed_data}}
      
      Check for completeness and accuracy.
    
    servers: []
    
    error_handling:
      on_failure: continue
    
    output: validation_result
  
  # Step 4: Final report (always runs)
  - name: final_report
    description: "Generate final report with all available data"
    
    prompt: |
      Create final report:
      
      Original Query: {{input_data}}
      Primary Data: {{primary_data}}
      Processed Data: {{processed_data}}
      Validation: {{validation_result}}
      
      Compile into comprehensive report, noting any processing issues.
    
    servers: []
    output: report
